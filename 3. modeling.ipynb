{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 1: All is Function\n",
    "\n",
    "---\n",
    "\n",
    "Training PT. Astra Honda Motor with Pacmann AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buat semua menjadi fungsi\n",
    "- `train_model`\n",
    "- `get_best_model`\n",
    "- `get_best_threshold`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fungsi `create_model_param` dan `create_model_object`\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Kita mesti memiliki beberapa model\n",
    "- Misal\n",
    "  - KNN\n",
    "  - Decision Tree\n",
    "  - Logistic Regression\n",
    "  - Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Kita definisikan parameternya dalam bentuk fungsi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_param():\n",
    "    \"\"\"Create the model objects\"\"\"\n",
    "    knn_params = {\n",
    "        'n_neighbors': [50, 100, 200],\n",
    "    }\n",
    "\n",
    "    dt_params = {\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'max_depth': [5, 10, None]\n",
    "    }\n",
    "    \n",
    "    lgr_params = {\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'C': [0.01, 0.1],\n",
    "        'max_iter': [100, 300, 500]\n",
    "    }\n",
    "\n",
    "    rf_params = {\n",
    "        'n_estimators': [100, 200, 300]\n",
    "    }\n",
    "\n",
    "    # Create model params\n",
    "    list_of_param = {\n",
    "        'KNeighborsClassifier': knn_params,\n",
    "        'DecisionTreeClassifier': dt_params,\n",
    "        'LogisticRegression': lgr_params,\n",
    "        'RandomForestClassifier': rf_params\n",
    "    }\n",
    "\n",
    "    return list_of_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'KNeighborsClassifier': {'n_neighbors': [50, 100, 200]},\n",
       " 'DecisionTreeClassifier': {'criterion': ['gini', 'entropy'],\n",
       "  'max_depth': [5, 10, None]},\n",
       " 'LogisticRegression': {'penalty': ['l1', 'l2'],\n",
       "  'C': [0.01, 0.1],\n",
       "  'max_iter': [100, 300, 500]},\n",
       " 'RandomForestClassifier': {'n_estimators': [100, 200, 300]}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_param = create_model_param()\n",
    "list_of_param"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Definisikan model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buat fungsi untuk membuat model\n",
    "def create_model_object():\n",
    "    \"\"\"Create the model objects\"\"\"\n",
    "    print(\"Creating model objects\")\n",
    "\n",
    "    # Create model objects\n",
    "    knn = KNeighborsClassifier()\n",
    "    lgr = LogisticRegression(solver='liblinear')\n",
    "    dt = DecisionTreeClassifier(random_state=123)\n",
    "    rf = RandomForestClassifier(random_state=123)\n",
    "\n",
    "    # Create list of model\n",
    "    list_of_model = [\n",
    "        {'model_name': knn.__class__.__name__, 'model_object': knn},\n",
    "        {'model_name': lgr.__class__.__name__, 'model_object': lgr},\n",
    "        {'model_name': dt.__class__.__name__, 'model_object': dt},\n",
    "        {'model_name': rf.__class__.__name__, 'model_object': rf}\n",
    "    ]\n",
    "\n",
    "    return list_of_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model objects\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'model_name': 'KNeighborsClassifier',\n",
       "  'model_object': KNeighborsClassifier()},\n",
       " {'model_name': 'LogisticRegression',\n",
       "  'model_object': LogisticRegression(solver='liblinear')},\n",
       " {'model_name': 'DecisionTreeClassifier',\n",
       "  'model_object': DecisionTreeClassifier(random_state=123)},\n",
       " {'model_name': 'RandomForestClassifier',\n",
       "  'model_object': RandomForestClassifier(random_state=123)}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Panggil\n",
    "list_of_model = create_model_object()\n",
    "list_of_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fungsi `train_model`\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Kita akan melakukan cross-validation pada tahap ini.\n",
    "- Untuk metriknya, kita pakai ROC AUC score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library\n",
    "import src.utils as utils\n",
    "import copy as copy\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dump beberapa hal\n",
    "  - list parameter model\n",
    "  - list model object\n",
    "  - list model yang sudah di tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'raw_dataset_path': 'data/raw/machining_maintenance.csv',\n",
       " 'dataset_path': 'data/output/data.pkl',\n",
       " 'input_set_path': 'data/output/input.pkl',\n",
       " 'output_set_path': 'data/output/output.pkl',\n",
       " 'input_cols_path': 'data/output/input_cols.pkl',\n",
       " 'train_set_path': ['data/output/X_train.pkl', 'data/output/y_train.pkl'],\n",
       " 'valid_set_path': ['data/output/X_valid.pkl', 'data/output/y_valid.pkl'],\n",
       " 'test_set_path': ['data/output/X_test.pkl', 'data/output/y_test.pkl'],\n",
       " 'output_cols': 'Failure Type',\n",
       " 'drop_cols': ['Product ID', 'Failure Type'],\n",
       " 'seed': 123,\n",
       " 'test_size': 0.2,\n",
       " 'num_cols': ['Air temperature [K]',\n",
       "  'Process temperature [K]',\n",
       "  'Rotational speed [rpm]',\n",
       "  'Torque [Nm]',\n",
       "  'Tool wear [min]'],\n",
       " 'cat_cols': ['Type'],\n",
       " 'num_imputer_path': 'data/output/num_imputer.pkl',\n",
       " 'cat_imputer_path': 'data/output/cat_imputer.pkl',\n",
       " 'scaler_path': 'data/output/scaler.pkl',\n",
       " 'train_clean_path': 'data/output/X_train_clean.pkl',\n",
       " 'valid_clean_path': 'data/output/X_valid_clean.pkl',\n",
       " 'test_clean_path': 'data/output/X_test_clean.pkl',\n",
       " 'list_of_model_path': 'log/list_of_model.pkl',\n",
       " 'list_of_param_path': 'log/list_of_param.pkl',\n",
       " 'list_of_tuned_model_path': 'log/list_of_tuned_model.pkl',\n",
       " 'best_model_path': 'models/best_model.pkl',\n",
       " 'best_threshold_path': 'models/best_threshold.pkl'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load config data\n",
    "CONFIG_DATA = utils.config_load()\n",
    "CONFIG_DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    # Load dataset\n",
    "    # Hanya menggunakan data train & valid\n",
    "    X_train = utils.pickle_load(CONFIG_DATA['train_clean_path'])\n",
    "    y_train = utils.pickle_load(CONFIG_DATA['train_set_path'][1])\n",
    "    X_valid = utils.pickle_load(CONFIG_DATA['valid_clean_path'])\n",
    "    y_valid = utils.pickle_load(CONFIG_DATA['valid_set_path'][1])\n",
    "    \n",
    "    # Create list of params & models\n",
    "    list_of_param = create_model_param()\n",
    "    list_of_model = create_model_object()\n",
    "\n",
    "    # List of trained model\n",
    "    list_of_tuned_model = {}\n",
    "\n",
    "    # Train model\n",
    "    for base_model in list_of_model:\n",
    "        # Current condition\n",
    "        model_name = base_model['model_name']\n",
    "        model_obj = copy.deepcopy(base_model['model_object'])\n",
    "        model_param = list_of_param[model_name]\n",
    "\n",
    "        # Debug message\n",
    "        print('Training model :', model_name)\n",
    "\n",
    "        # Create model object\n",
    "        model = GridSearchCV(estimator = model_obj,\n",
    "                             param_grid = model_param,\n",
    "                             cv = 5,\n",
    "                             verbose=10,\n",
    "                             scoring = 'roc_auc')\n",
    "        \n",
    "        # Train model\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Predict\n",
    "        y_pred_proba_train = model.predict_proba(X_train)[:, 1]\n",
    "        y_pred_proba_valid = model.predict_proba(X_valid)[:, 1]\n",
    "        \n",
    "        # Get score\n",
    "        train_score = roc_auc_score(y_train, y_pred_proba_train)\n",
    "        valid_score = roc_auc_score(y_valid, y_pred_proba_valid)\n",
    "\n",
    "        # Append\n",
    "        list_of_tuned_model[model_name] = {\n",
    "            'model': model,\n",
    "            'train_auc': train_score,\n",
    "            'valid_auc': valid_score,\n",
    "            'best_params': model.best_params_\n",
    "        }\n",
    "\n",
    "        print(\"Done training\")\n",
    "        print(\"\")\n",
    "\n",
    "    # Dump data\n",
    "    utils.pickle_dump(list_of_param, CONFIG_DATA['list_of_param_path'])\n",
    "    utils.pickle_dump(list_of_model, CONFIG_DATA['list_of_model_path'])\n",
    "    utils.pickle_dump(list_of_tuned_model, CONFIG_DATA['list_of_tuned_model_path'])\n",
    "\n",
    "    return list_of_param, list_of_model, list_of_tuned_model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model objects\n",
      "Training model : KNeighborsClassifier\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV 1/5; 1/3] START n_neighbors=50..............................................\n",
      "[CV 1/5; 1/3] END ...............n_neighbors=50;, score=0.897 total time=   0.1s\n",
      "[CV 2/5; 1/3] START n_neighbors=50..............................................\n",
      "[CV 2/5; 1/3] END ...............n_neighbors=50;, score=0.961 total time=   0.1s\n",
      "[CV 3/5; 1/3] START n_neighbors=50..............................................\n",
      "[CV 3/5; 1/3] END ...............n_neighbors=50;, score=0.943 total time=   0.1s\n",
      "[CV 4/5; 1/3] START n_neighbors=50..............................................\n",
      "[CV 4/5; 1/3] END ...............n_neighbors=50;, score=0.936 total time=   0.1s\n",
      "[CV 5/5; 1/3] START n_neighbors=50..............................................\n",
      "[CV 5/5; 1/3] END ...............n_neighbors=50;, score=0.959 total time=   0.1s\n",
      "[CV 1/5; 2/3] START n_neighbors=100.............................................\n",
      "[CV 1/5; 2/3] END ..............n_neighbors=100;, score=0.897 total time=   0.1s\n",
      "[CV 2/5; 2/3] START n_neighbors=100.............................................\n",
      "[CV 2/5; 2/3] END ..............n_neighbors=100;, score=0.957 total time=   0.1s\n",
      "[CV 3/5; 2/3] START n_neighbors=100.............................................\n",
      "[CV 3/5; 2/3] END ..............n_neighbors=100;, score=0.939 total time=   0.1s\n",
      "[CV 4/5; 2/3] START n_neighbors=100.............................................\n",
      "[CV 4/5; 2/3] END ..............n_neighbors=100;, score=0.934 total time=   0.1s\n",
      "[CV 5/5; 2/3] START n_neighbors=100.............................................\n",
      "[CV 5/5; 2/3] END ..............n_neighbors=100;, score=0.952 total time=   0.1s\n",
      "[CV 1/5; 3/3] START n_neighbors=200.............................................\n",
      "[CV 1/5; 3/3] END ..............n_neighbors=200;, score=0.902 total time=   0.2s\n",
      "[CV 2/5; 3/3] START n_neighbors=200.............................................\n",
      "[CV 2/5; 3/3] END ..............n_neighbors=200;, score=0.951 total time=   0.1s\n",
      "[CV 3/5; 3/3] START n_neighbors=200.............................................\n",
      "[CV 3/5; 3/3] END ..............n_neighbors=200;, score=0.938 total time=   0.1s\n",
      "[CV 4/5; 3/3] START n_neighbors=200.............................................\n",
      "[CV 4/5; 3/3] END ..............n_neighbors=200;, score=0.928 total time=   0.2s\n",
      "[CV 5/5; 3/3] START n_neighbors=200.............................................\n",
      "[CV 5/5; 3/3] END ..............n_neighbors=200;, score=0.947 total time=   0.1s\n",
      "Done training\n",
      "\n",
      "Training model : LogisticRegression\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV 1/5; 1/12] START C=0.01, max_iter=100, penalty=l1...........................\n",
      "[CV 1/5; 1/12] END C=0.01, max_iter=100, penalty=l1;, score=0.738 total time=   0.1s\n",
      "[CV 2/5; 1/12] START C=0.01, max_iter=100, penalty=l1...........................\n",
      "[CV 2/5; 1/12] END C=0.01, max_iter=100, penalty=l1;, score=0.777 total time=   0.0s\n",
      "[CV 3/5; 1/12] START C=0.01, max_iter=100, penalty=l1...........................\n",
      "[CV 3/5; 1/12] END C=0.01, max_iter=100, penalty=l1;, score=0.796 total time=   0.0s\n",
      "[CV 4/5; 1/12] START C=0.01, max_iter=100, penalty=l1...........................\n",
      "[CV 4/5; 1/12] END C=0.01, max_iter=100, penalty=l1;, score=0.796 total time=   0.0s\n",
      "[CV 5/5; 1/12] START C=0.01, max_iter=100, penalty=l1...........................\n",
      "[CV 5/5; 1/12] END C=0.01, max_iter=100, penalty=l1;, score=0.794 total time=   0.0s\n",
      "[CV 1/5; 2/12] START C=0.01, max_iter=100, penalty=l2...........................\n",
      "[CV 1/5; 2/12] END C=0.01, max_iter=100, penalty=l2;, score=0.853 total time=   0.1s\n",
      "[CV 2/5; 2/12] START C=0.01, max_iter=100, penalty=l2...........................\n",
      "[CV 2/5; 2/12] END C=0.01, max_iter=100, penalty=l2;, score=0.837 total time=   0.0s\n",
      "[CV 3/5; 2/12] START C=0.01, max_iter=100, penalty=l2...........................\n",
      "[CV 3/5; 2/12] END C=0.01, max_iter=100, penalty=l2;, score=0.885 total time=   0.0s\n",
      "[CV 4/5; 2/12] START C=0.01, max_iter=100, penalty=l2...........................\n",
      "[CV 4/5; 2/12] END C=0.01, max_iter=100, penalty=l2;, score=0.907 total time=   0.0s\n",
      "[CV 5/5; 2/12] START C=0.01, max_iter=100, penalty=l2...........................\n",
      "[CV 5/5; 2/12] END C=0.01, max_iter=100, penalty=l2;, score=0.885 total time=   0.0s\n",
      "[CV 1/5; 3/12] START C=0.01, max_iter=300, penalty=l1...........................\n",
      "[CV 1/5; 3/12] END C=0.01, max_iter=300, penalty=l1;, score=0.738 total time=   0.1s\n",
      "[CV 2/5; 3/12] START C=0.01, max_iter=300, penalty=l1...........................\n",
      "[CV 2/5; 3/12] END C=0.01, max_iter=300, penalty=l1;, score=0.777 total time=   0.1s\n",
      "[CV 3/5; 3/12] START C=0.01, max_iter=300, penalty=l1...........................\n",
      "[CV 3/5; 3/12] END C=0.01, max_iter=300, penalty=l1;, score=0.796 total time=   0.0s\n",
      "[CV 4/5; 3/12] START C=0.01, max_iter=300, penalty=l1...........................\n",
      "[CV 4/5; 3/12] END C=0.01, max_iter=300, penalty=l1;, score=0.796 total time=   0.0s\n",
      "[CV 5/5; 3/12] START C=0.01, max_iter=300, penalty=l1...........................\n",
      "[CV 5/5; 3/12] END C=0.01, max_iter=300, penalty=l1;, score=0.794 total time=   0.0s\n",
      "[CV 1/5; 4/12] START C=0.01, max_iter=300, penalty=l2...........................\n",
      "[CV 1/5; 4/12] END C=0.01, max_iter=300, penalty=l2;, score=0.853 total time=   0.0s\n",
      "[CV 2/5; 4/12] START C=0.01, max_iter=300, penalty=l2...........................\n",
      "[CV 2/5; 4/12] END C=0.01, max_iter=300, penalty=l2;, score=0.837 total time=   0.0s\n",
      "[CV 3/5; 4/12] START C=0.01, max_iter=300, penalty=l2...........................\n",
      "[CV 3/5; 4/12] END C=0.01, max_iter=300, penalty=l2;, score=0.885 total time=   0.0s\n",
      "[CV 4/5; 4/12] START C=0.01, max_iter=300, penalty=l2...........................\n",
      "[CV 4/5; 4/12] END C=0.01, max_iter=300, penalty=l2;, score=0.907 total time=   0.0s\n",
      "[CV 5/5; 4/12] START C=0.01, max_iter=300, penalty=l2...........................\n",
      "[CV 5/5; 4/12] END C=0.01, max_iter=300, penalty=l2;, score=0.885 total time=   0.0s\n",
      "[CV 1/5; 5/12] START C=0.01, max_iter=500, penalty=l1...........................\n",
      "[CV 1/5; 5/12] END C=0.01, max_iter=500, penalty=l1;, score=0.738 total time=   0.0s\n",
      "[CV 2/5; 5/12] START C=0.01, max_iter=500, penalty=l1...........................\n",
      "[CV 2/5; 5/12] END C=0.01, max_iter=500, penalty=l1;, score=0.777 total time=   0.0s\n",
      "[CV 3/5; 5/12] START C=0.01, max_iter=500, penalty=l1...........................\n",
      "[CV 3/5; 5/12] END C=0.01, max_iter=500, penalty=l1;, score=0.796 total time=   0.0s\n",
      "[CV 4/5; 5/12] START C=0.01, max_iter=500, penalty=l1...........................\n",
      "[CV 4/5; 5/12] END C=0.01, max_iter=500, penalty=l1;, score=0.796 total time=   0.0s\n",
      "[CV 5/5; 5/12] START C=0.01, max_iter=500, penalty=l1...........................\n",
      "[CV 5/5; 5/12] END C=0.01, max_iter=500, penalty=l1;, score=0.794 total time=   0.0s\n",
      "[CV 1/5; 6/12] START C=0.01, max_iter=500, penalty=l2...........................\n",
      "[CV 1/5; 6/12] END C=0.01, max_iter=500, penalty=l2;, score=0.853 total time=   0.0s\n",
      "[CV 2/5; 6/12] START C=0.01, max_iter=500, penalty=l2...........................\n",
      "[CV 2/5; 6/12] END C=0.01, max_iter=500, penalty=l2;, score=0.837 total time=   0.0s\n",
      "[CV 3/5; 6/12] START C=0.01, max_iter=500, penalty=l2...........................\n",
      "[CV 3/5; 6/12] END C=0.01, max_iter=500, penalty=l2;, score=0.885 total time=   0.0s\n",
      "[CV 4/5; 6/12] START C=0.01, max_iter=500, penalty=l2...........................\n",
      "[CV 4/5; 6/12] END C=0.01, max_iter=500, penalty=l2;, score=0.907 total time=   0.1s\n",
      "[CV 5/5; 6/12] START C=0.01, max_iter=500, penalty=l2...........................\n",
      "[CV 5/5; 6/12] END C=0.01, max_iter=500, penalty=l2;, score=0.885 total time=   0.1s\n",
      "[CV 1/5; 7/12] START C=0.1, max_iter=100, penalty=l1............................\n",
      "[CV 1/5; 7/12] END C=0.1, max_iter=100, penalty=l1;, score=0.866 total time=   0.1s\n",
      "[CV 2/5; 7/12] START C=0.1, max_iter=100, penalty=l1............................\n",
      "[CV 2/5; 7/12] END C=0.1, max_iter=100, penalty=l1;, score=0.871 total time=   0.1s\n",
      "[CV 3/5; 7/12] START C=0.1, max_iter=100, penalty=l1............................\n",
      "[CV 3/5; 7/12] END C=0.1, max_iter=100, penalty=l1;, score=0.889 total time=   0.1s\n",
      "[CV 4/5; 7/12] START C=0.1, max_iter=100, penalty=l1............................\n",
      "[CV 4/5; 7/12] END C=0.1, max_iter=100, penalty=l1;, score=0.926 total time=   0.1s\n",
      "[CV 5/5; 7/12] START C=0.1, max_iter=100, penalty=l1............................\n",
      "[CV 5/5; 7/12] END C=0.1, max_iter=100, penalty=l1;, score=0.897 total time=   0.0s\n",
      "[CV 1/5; 8/12] START C=0.1, max_iter=100, penalty=l2............................\n",
      "[CV 1/5; 8/12] END C=0.1, max_iter=100, penalty=l2;, score=0.869 total time=   0.0s\n",
      "[CV 2/5; 8/12] START C=0.1, max_iter=100, penalty=l2............................\n",
      "[CV 2/5; 8/12] END C=0.1, max_iter=100, penalty=l2;, score=0.880 total time=   0.1s\n",
      "[CV 3/5; 8/12] START C=0.1, max_iter=100, penalty=l2............................\n",
      "[CV 3/5; 8/12] END C=0.1, max_iter=100, penalty=l2;, score=0.896 total time=   0.1s\n",
      "[CV 4/5; 8/12] START C=0.1, max_iter=100, penalty=l2............................\n",
      "[CV 4/5; 8/12] END C=0.1, max_iter=100, penalty=l2;, score=0.928 total time=   0.1s\n",
      "[CV 5/5; 8/12] START C=0.1, max_iter=100, penalty=l2............................\n",
      "[CV 5/5; 8/12] END C=0.1, max_iter=100, penalty=l2;, score=0.901 total time=   0.1s\n",
      "[CV 1/5; 9/12] START C=0.1, max_iter=300, penalty=l1............................\n",
      "[CV 1/5; 9/12] END C=0.1, max_iter=300, penalty=l1;, score=0.866 total time=   0.1s\n",
      "[CV 2/5; 9/12] START C=0.1, max_iter=300, penalty=l1............................\n",
      "[CV 2/5; 9/12] END C=0.1, max_iter=300, penalty=l1;, score=0.871 total time=   0.1s\n",
      "[CV 3/5; 9/12] START C=0.1, max_iter=300, penalty=l1............................\n",
      "[CV 3/5; 9/12] END C=0.1, max_iter=300, penalty=l1;, score=0.889 total time=   0.0s\n",
      "[CV 4/5; 9/12] START C=0.1, max_iter=300, penalty=l1............................\n",
      "[CV 4/5; 9/12] END C=0.1, max_iter=300, penalty=l1;, score=0.926 total time=   0.0s\n",
      "[CV 5/5; 9/12] START C=0.1, max_iter=300, penalty=l1............................\n",
      "[CV 5/5; 9/12] END C=0.1, max_iter=300, penalty=l1;, score=0.897 total time=   0.0s\n",
      "[CV 1/5; 10/12] START C=0.1, max_iter=300, penalty=l2...........................\n",
      "[CV 1/5; 10/12] END C=0.1, max_iter=300, penalty=l2;, score=0.869 total time=   0.1s\n",
      "[CV 2/5; 10/12] START C=0.1, max_iter=300, penalty=l2...........................\n",
      "[CV 2/5; 10/12] END C=0.1, max_iter=300, penalty=l2;, score=0.880 total time=   0.0s\n",
      "[CV 3/5; 10/12] START C=0.1, max_iter=300, penalty=l2...........................\n",
      "[CV 3/5; 10/12] END C=0.1, max_iter=300, penalty=l2;, score=0.896 total time=   0.1s\n",
      "[CV 4/5; 10/12] START C=0.1, max_iter=300, penalty=l2...........................\n",
      "[CV 4/5; 10/12] END C=0.1, max_iter=300, penalty=l2;, score=0.928 total time=   0.1s\n",
      "[CV 5/5; 10/12] START C=0.1, max_iter=300, penalty=l2...........................\n",
      "[CV 5/5; 10/12] END C=0.1, max_iter=300, penalty=l2;, score=0.901 total time=   0.0s\n",
      "[CV 1/5; 11/12] START C=0.1, max_iter=500, penalty=l1...........................\n",
      "[CV 1/5; 11/12] END C=0.1, max_iter=500, penalty=l1;, score=0.866 total time=   0.1s\n",
      "[CV 2/5; 11/12] START C=0.1, max_iter=500, penalty=l1...........................\n",
      "[CV 2/5; 11/12] END C=0.1, max_iter=500, penalty=l1;, score=0.871 total time=   0.1s\n",
      "[CV 3/5; 11/12] START C=0.1, max_iter=500, penalty=l1...........................\n",
      "[CV 3/5; 11/12] END C=0.1, max_iter=500, penalty=l1;, score=0.889 total time=   0.1s\n",
      "[CV 4/5; 11/12] START C=0.1, max_iter=500, penalty=l1...........................\n",
      "[CV 4/5; 11/12] END C=0.1, max_iter=500, penalty=l1;, score=0.926 total time=   0.1s\n",
      "[CV 5/5; 11/12] START C=0.1, max_iter=500, penalty=l1...........................\n",
      "[CV 5/5; 11/12] END C=0.1, max_iter=500, penalty=l1;, score=0.897 total time=   0.1s\n",
      "[CV 1/5; 12/12] START C=0.1, max_iter=500, penalty=l2...........................\n",
      "[CV 1/5; 12/12] END C=0.1, max_iter=500, penalty=l2;, score=0.869 total time=   0.1s\n",
      "[CV 2/5; 12/12] START C=0.1, max_iter=500, penalty=l2...........................\n",
      "[CV 2/5; 12/12] END C=0.1, max_iter=500, penalty=l2;, score=0.880 total time=   0.1s\n",
      "[CV 3/5; 12/12] START C=0.1, max_iter=500, penalty=l2...........................\n",
      "[CV 3/5; 12/12] END C=0.1, max_iter=500, penalty=l2;, score=0.896 total time=   0.1s\n",
      "[CV 4/5; 12/12] START C=0.1, max_iter=500, penalty=l2...........................\n",
      "[CV 4/5; 12/12] END C=0.1, max_iter=500, penalty=l2;, score=0.928 total time=   0.0s\n",
      "[CV 5/5; 12/12] START C=0.1, max_iter=500, penalty=l2...........................\n",
      "[CV 5/5; 12/12] END C=0.1, max_iter=500, penalty=l2;, score=0.901 total time=   0.0s\n",
      "Done training\n",
      "\n",
      "Training model : DecisionTreeClassifier\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[CV 1/5; 1/6] START criterion=gini, max_depth=5.................................\n",
      "[CV 1/5; 1/6] END ..criterion=gini, max_depth=5;, score=0.838 total time=   0.1s\n",
      "[CV 2/5; 1/6] START criterion=gini, max_depth=5.................................\n",
      "[CV 2/5; 1/6] END ..criterion=gini, max_depth=5;, score=0.912 total time=   0.1s\n",
      "[CV 3/5; 1/6] START criterion=gini, max_depth=5.................................\n",
      "[CV 3/5; 1/6] END ..criterion=gini, max_depth=5;, score=0.904 total time=   0.1s\n",
      "[CV 4/5; 1/6] START criterion=gini, max_depth=5.................................\n",
      "[CV 4/5; 1/6] END ..criterion=gini, max_depth=5;, score=0.919 total time=   0.1s\n",
      "[CV 5/5; 1/6] START criterion=gini, max_depth=5.................................\n",
      "[CV 5/5; 1/6] END ..criterion=gini, max_depth=5;, score=0.917 total time=   0.1s\n",
      "[CV 1/5; 2/6] START criterion=gini, max_depth=10................................\n",
      "[CV 1/5; 2/6] END .criterion=gini, max_depth=10;, score=0.860 total time=   0.1s\n",
      "[CV 2/5; 2/6] START criterion=gini, max_depth=10................................\n",
      "[CV 2/5; 2/6] END .criterion=gini, max_depth=10;, score=0.864 total time=   0.1s\n",
      "[CV 3/5; 2/6] START criterion=gini, max_depth=10................................\n",
      "[CV 3/5; 2/6] END .criterion=gini, max_depth=10;, score=0.826 total time=   0.1s\n",
      "[CV 4/5; 2/6] START criterion=gini, max_depth=10................................\n",
      "[CV 4/5; 2/6] END .criterion=gini, max_depth=10;, score=0.899 total time=   0.1s\n",
      "[CV 5/5; 2/6] START criterion=gini, max_depth=10................................\n",
      "[CV 5/5; 2/6] END .criterion=gini, max_depth=10;, score=0.931 total time=   0.1s\n",
      "[CV 1/5; 3/6] START criterion=gini, max_depth=None..............................\n",
      "[CV 1/5; 3/6] END criterion=gini, max_depth=None;, score=0.836 total time=   0.1s\n",
      "[CV 2/5; 3/6] START criterion=gini, max_depth=None..............................\n",
      "[CV 2/5; 3/6] END criterion=gini, max_depth=None;, score=0.859 total time=   0.1s\n",
      "[CV 3/5; 3/6] START criterion=gini, max_depth=None..............................\n",
      "[CV 3/5; 3/6] END criterion=gini, max_depth=None;, score=0.812 total time=   0.1s\n",
      "[CV 4/5; 3/6] START criterion=gini, max_depth=None..............................\n",
      "[CV 4/5; 3/6] END criterion=gini, max_depth=None;, score=0.850 total time=   0.1s\n",
      "[CV 5/5; 3/6] START criterion=gini, max_depth=None..............................\n",
      "[CV 5/5; 3/6] END criterion=gini, max_depth=None;, score=0.904 total time=   0.1s\n",
      "[CV 1/5; 4/6] START criterion=entropy, max_depth=5..............................\n",
      "[CV 1/5; 4/6] END criterion=entropy, max_depth=5;, score=0.858 total time=   0.1s\n",
      "[CV 2/5; 4/6] START criterion=entropy, max_depth=5..............................\n",
      "[CV 2/5; 4/6] END criterion=entropy, max_depth=5;, score=0.967 total time=   0.1s\n",
      "[CV 3/5; 4/6] START criterion=entropy, max_depth=5..............................\n",
      "[CV 3/5; 4/6] END criterion=entropy, max_depth=5;, score=0.915 total time=   0.1s\n",
      "[CV 4/5; 4/6] START criterion=entropy, max_depth=5..............................\n",
      "[CV 4/5; 4/6] END criterion=entropy, max_depth=5;, score=0.945 total time=   0.1s\n",
      "[CV 5/5; 4/6] START criterion=entropy, max_depth=5..............................\n",
      "[CV 5/5; 4/6] END criterion=entropy, max_depth=5;, score=0.945 total time=   0.1s\n",
      "[CV 1/5; 5/6] START criterion=entropy, max_depth=10.............................\n",
      "[CV 1/5; 5/6] END criterion=entropy, max_depth=10;, score=0.864 total time=   0.1s\n",
      "[CV 2/5; 5/6] START criterion=entropy, max_depth=10.............................\n",
      "[CV 2/5; 5/6] END criterion=entropy, max_depth=10;, score=0.915 total time=   0.1s\n",
      "[CV 3/5; 5/6] START criterion=entropy, max_depth=10.............................\n",
      "[CV 3/5; 5/6] END criterion=entropy, max_depth=10;, score=0.853 total time=   0.1s\n",
      "[CV 4/5; 5/6] START criterion=entropy, max_depth=10.............................\n",
      "[CV 4/5; 5/6] END criterion=entropy, max_depth=10;, score=0.848 total time=   0.0s\n",
      "[CV 5/5; 5/6] START criterion=entropy, max_depth=10.............................\n",
      "[CV 5/5; 5/6] END criterion=entropy, max_depth=10;, score=0.882 total time=   0.0s\n",
      "[CV 1/5; 6/6] START criterion=entropy, max_depth=None...........................\n",
      "[CV 1/5; 6/6] END criterion=entropy, max_depth=None;, score=0.826 total time=   0.0s\n",
      "[CV 2/5; 6/6] START criterion=entropy, max_depth=None...........................\n",
      "[CV 2/5; 6/6] END criterion=entropy, max_depth=None;, score=0.928 total time=   0.0s\n",
      "[CV 3/5; 6/6] START criterion=entropy, max_depth=None...........................\n",
      "[CV 3/5; 6/6] END criterion=entropy, max_depth=None;, score=0.802 total time=   0.1s\n",
      "[CV 4/5; 6/6] START criterion=entropy, max_depth=None...........................\n",
      "[CV 4/5; 6/6] END criterion=entropy, max_depth=None;, score=0.805 total time=   0.0s\n",
      "[CV 5/5; 6/6] START criterion=entropy, max_depth=None...........................\n",
      "[CV 5/5; 6/6] END criterion=entropy, max_depth=None;, score=0.847 total time=   0.0s\n",
      "Done training\n",
      "\n",
      "Training model : RandomForestClassifier\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV 1/5; 1/3] START n_estimators=100............................................\n",
      "[CV 1/5; 1/3] END .............n_estimators=100;, score=0.928 total time=   1.2s\n",
      "[CV 2/5; 1/3] START n_estimators=100............................................\n",
      "[CV 2/5; 1/3] END .............n_estimators=100;, score=0.993 total time=   1.2s\n",
      "[CV 3/5; 1/3] START n_estimators=100............................................\n",
      "[CV 3/5; 1/3] END .............n_estimators=100;, score=0.984 total time=   1.3s\n",
      "[CV 4/5; 1/3] START n_estimators=100............................................\n",
      "[CV 4/5; 1/3] END .............n_estimators=100;, score=0.961 total time=   0.7s\n",
      "[CV 5/5; 1/3] START n_estimators=100............................................\n",
      "[CV 5/5; 1/3] END .............n_estimators=100;, score=0.976 total time=   0.6s\n",
      "[CV 1/5; 2/3] START n_estimators=200............................................\n",
      "[CV 1/5; 2/3] END .............n_estimators=200;, score=0.924 total time=   1.7s\n",
      "[CV 2/5; 2/3] START n_estimators=200............................................\n",
      "[CV 2/5; 2/3] END .............n_estimators=200;, score=0.994 total time=   2.4s\n",
      "[CV 3/5; 2/3] START n_estimators=200............................................\n",
      "[CV 3/5; 2/3] END .............n_estimators=200;, score=0.983 total time=   1.8s\n",
      "[CV 4/5; 2/3] START n_estimators=200............................................\n",
      "[CV 4/5; 2/3] END .............n_estimators=200;, score=0.968 total time=   1.7s\n",
      "[CV 5/5; 2/3] START n_estimators=200............................................\n",
      "[CV 5/5; 2/3] END .............n_estimators=200;, score=0.974 total time=   1.2s\n",
      "[CV 1/5; 3/3] START n_estimators=300............................................\n",
      "[CV 1/5; 3/3] END .............n_estimators=300;, score=0.921 total time=   2.1s\n",
      "[CV 2/5; 3/3] START n_estimators=300............................................\n",
      "[CV 2/5; 3/3] END .............n_estimators=300;, score=0.994 total time=   2.6s\n",
      "[CV 3/5; 3/3] START n_estimators=300............................................\n",
      "[CV 3/5; 3/3] END .............n_estimators=300;, score=0.984 total time=   3.1s\n",
      "[CV 4/5; 3/3] START n_estimators=300............................................\n",
      "[CV 4/5; 3/3] END .............n_estimators=300;, score=0.969 total time=   2.9s\n",
      "[CV 5/5; 3/3] START n_estimators=300............................................\n",
      "[CV 5/5; 3/3] END .............n_estimators=300;, score=0.973 total time=   4.1s\n",
      "Done training\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Lakukan training\n",
    "list_of_param, list_of_model, list_of_tuned_model = train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'KNeighborsClassifier': {'model': GridSearchCV(cv=5, estimator=KNeighborsClassifier(),\n",
       "               param_grid={'n_neighbors': [50, 100, 200]}, scoring='roc_auc',\n",
       "               verbose=10),\n",
       "  'train_auc': 0.9700419098282484,\n",
       "  'valid_auc': 0.9014214008142116,\n",
       "  'best_params': {'n_neighbors': 50}},\n",
       " 'LogisticRegression': {'model': GridSearchCV(cv=5, estimator=LogisticRegression(solver='liblinear'),\n",
       "               param_grid={'C': [0.01, 0.1], 'max_iter': [100, 300, 500],\n",
       "                           'penalty': ['l1', 'l2']},\n",
       "               scoring='roc_auc', verbose=10),\n",
       "  'train_auc': 0.8974317470594583,\n",
       "  'valid_auc': 0.8716228719467062,\n",
       "  'best_params': {'C': 0.1, 'max_iter': 100, 'penalty': 'l2'}},\n",
       " 'DecisionTreeClassifier': {'model': GridSearchCV(cv=5, estimator=DecisionTreeClassifier(random_state=123),\n",
       "               param_grid={'criterion': ['gini', 'entropy'],\n",
       "                           'max_depth': [5, 10, None]},\n",
       "               scoring='roc_auc', verbose=10),\n",
       "  'train_auc': 0.9817570484048309,\n",
       "  'valid_auc': 0.896078136565507,\n",
       "  'best_params': {'criterion': 'entropy', 'max_depth': 5}},\n",
       " 'RandomForestClassifier': {'model': GridSearchCV(cv=5, estimator=RandomForestClassifier(random_state=123),\n",
       "               param_grid={'n_estimators': [100, 200, 300]}, scoring='roc_auc',\n",
       "               verbose=10),\n",
       "  'train_auc': 1.0,\n",
       "  'valid_auc': 0.9309944022945966,\n",
       "  'best_params': {'n_estimators': 200}}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print hasil model yang sudah dituning\n",
    "list_of_tuned_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fungsi `get_best_model`\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fungsi untuk mencari model terbaik dari hasil tuning.\n",
    "- Berarti model yang memiliki ROC AUC yang paling oke\n",
    "- Dump best_model parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'raw_dataset_path': 'data/raw/machining_maintenance.csv',\n",
       " 'dataset_path': 'data/output/data.pkl',\n",
       " 'input_set_path': 'data/output/input.pkl',\n",
       " 'output_set_path': 'data/output/output.pkl',\n",
       " 'input_cols_path': 'data/output/input_cols.pkl',\n",
       " 'train_set_path': ['data/output/X_train.pkl', 'data/output/y_train.pkl'],\n",
       " 'valid_set_path': ['data/output/X_valid.pkl', 'data/output/y_valid.pkl'],\n",
       " 'test_set_path': ['data/output/X_test.pkl', 'data/output/y_test.pkl'],\n",
       " 'output_cols': 'Failure Type',\n",
       " 'drop_cols': ['Product ID', 'Failure Type'],\n",
       " 'seed': 123,\n",
       " 'test_size': 0.2,\n",
       " 'num_cols': ['Air temperature [K]',\n",
       "  'Process temperature [K]',\n",
       "  'Rotational speed [rpm]',\n",
       "  'Torque [Nm]',\n",
       "  'Tool wear [min]'],\n",
       " 'cat_cols': ['Type'],\n",
       " 'num_imputer_path': 'data/output/num_imputer.pkl',\n",
       " 'cat_imputer_path': 'data/output/cat_imputer.pkl',\n",
       " 'scaler_path': 'data/output/scaler.pkl',\n",
       " 'train_clean_path': 'data/output/X_train_clean.pkl',\n",
       " 'valid_clean_path': 'data/output/X_valid_clean.pkl',\n",
       " 'test_clean_path': 'data/output/X_test_clean.pkl',\n",
       " 'list_of_model_path': 'log/list_of_model.pkl',\n",
       " 'list_of_param_path': 'log/list_of_param.pkl',\n",
       " 'list_of_tuned_model_path': 'log/list_of_tuned_model.pkl',\n",
       " 'best_model_path': 'models/best_model.pkl',\n",
       " 'best_threshold_path': 'models/best_threshold.pkl'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONFIG_DATA = utils.config_load()\n",
    "CONFIG_DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_model():\n",
    "    # Load tuned model\n",
    "    list_of_tuned_model = utils.pickle_load(CONFIG_DATA['list_of_tuned_model_path'])\n",
    "\n",
    "    # Get the best model\n",
    "    best_model_name = None\n",
    "    best_model = None\n",
    "    best_performance = -99999\n",
    "    best_model_param = None\n",
    "\n",
    "    for model_name, model in list_of_tuned_model.items():\n",
    "        if model['valid_auc'] > best_performance:\n",
    "            best_model_name = model_name\n",
    "            best_model = model['model']\n",
    "            best_performance = model['valid_auc']\n",
    "            best_model_param = model['best_params']\n",
    "\n",
    "    # Dump the best model\n",
    "    utils.pickle_dump(best_model, CONFIG_DATA['best_model_path'])\n",
    "\n",
    "    # Print\n",
    "    print('=============================================')\n",
    "    print('Best model        :', best_model_name)\n",
    "    print('Metric score      :', best_performance)\n",
    "    print('Best model params :', best_model_param)\n",
    "    print('=============================================')\n",
    "\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================\n",
      "Best model        : RandomForestClassifier\n",
      "Metric score      : 0.9309944022945966\n",
      "Best model params : {'n_estimators': 200}\n",
      "=============================================\n"
     ]
    }
   ],
   "source": [
    "# Pilih best model\n",
    "best_model = get_best_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(random_state=123),\n",
       "             param_grid={&#x27;n_estimators&#x27;: [100, 200, 300]}, scoring=&#x27;roc_auc&#x27;,\n",
       "             verbose=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(random_state=123),\n",
       "             param_grid={&#x27;n_estimators&#x27;: [100, 200, 300]}, scoring=&#x27;roc_auc&#x27;,\n",
       "             verbose=10)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=123)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=123)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(random_state=123),\n",
       "             param_grid={'n_estimators': [100, 200, 300]}, scoring='roc_auc',\n",
       "             verbose=10)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fungsi `get_best_threshold` (tambahan)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Output dari klasifikasi bisa kita ibaratkan sebagai probability mendapatkan kelas 1.\n",
    "- Untuk konversi dari probability menjadi kelas, kita butuh threshold. Contoh\n",
    "- threshold = 0.3, maka P(y=1) = 0.4 masuk ke kelas 1.\n",
    "- Threshold ini akan mempengaruhi seberapa besar bertemu kasus False Positive.\n",
    "- Kita bisa optimalkan nilai `recall`\n",
    "- Buat fungsi & dump hasil thresholdnya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buat distribusi threshold dari 0-1 sebanyak 100 nilai\n",
    "# karena probability paling kecil adalah 0 dan paling besar adalah 1\n",
    "THRESHOLD = np.linspace(0, 1, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'raw_dataset_path': 'data/raw/machining_maintenance.csv',\n",
       " 'dataset_path': 'data/output/data.pkl',\n",
       " 'input_set_path': 'data/output/input.pkl',\n",
       " 'output_set_path': 'data/output/output.pkl',\n",
       " 'input_cols_path': 'data/output/input_cols.pkl',\n",
       " 'train_set_path': ['data/output/X_train.pkl', 'data/output/y_train.pkl'],\n",
       " 'valid_set_path': ['data/output/X_valid.pkl', 'data/output/y_valid.pkl'],\n",
       " 'test_set_path': ['data/output/X_test.pkl', 'data/output/y_test.pkl'],\n",
       " 'output_cols': 'Failure Type',\n",
       " 'drop_cols': ['Product ID', 'Failure Type'],\n",
       " 'seed': 123,\n",
       " 'test_size': 0.2,\n",
       " 'num_cols': ['Air temperature [K]',\n",
       "  'Process temperature [K]',\n",
       "  'Rotational speed [rpm]',\n",
       "  'Torque [Nm]',\n",
       "  'Tool wear [min]'],\n",
       " 'cat_cols': ['Type'],\n",
       " 'num_imputer_path': 'data/output/num_imputer.pkl',\n",
       " 'cat_imputer_path': 'data/output/cat_imputer.pkl',\n",
       " 'scaler_path': 'data/output/scaler.pkl',\n",
       " 'train_clean_path': 'data/output/X_train_clean.pkl',\n",
       " 'valid_clean_path': 'data/output/X_valid_clean.pkl',\n",
       " 'test_clean_path': 'data/output/X_test_clean.pkl',\n",
       " 'list_of_model_path': 'log/list_of_model.pkl',\n",
       " 'list_of_param_path': 'log/list_of_param.pkl',\n",
       " 'list_of_tuned_model_path': 'log/list_of_tuned_model.pkl',\n",
       " 'best_model_path': 'models/best_model.pkl',\n",
       " 'best_threshold_path': 'models/best_threshold.pkl'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Update config\n",
    "CONFIG_DATA = utils.config_load()\n",
    "CONFIG_DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buat fungsi\n",
    "def get_best_threshold():\n",
    "    # Load data & model\n",
    "    X_valid = utils.pickle_load(CONFIG_DATA['valid_clean_path'])\n",
    "    y_valid = utils.pickle_load(CONFIG_DATA['valid_set_path'][1])\n",
    "    best_model = utils.pickle_load(CONFIG_DATA['best_model_path'])\n",
    "\n",
    "    # Get the proba pred\n",
    "    y_pred_proba = best_model.predict_proba(X_valid)[:, 1]\n",
    "\n",
    "    # Initialize\n",
    "    metric_threshold = pd.Series([])\n",
    "    \n",
    "    # Optimize\n",
    "    for threshold_value in THRESHOLD:\n",
    "        # Get predictions\n",
    "        y_pred = (y_pred_proba >= threshold_value).astype(int)\n",
    "\n",
    "        # Get the F1 score\n",
    "        metric_score = recall_score(y_valid, y_pred, average='weighted')\n",
    "\n",
    "        # Add to the storage\n",
    "        metric_threshold[metric_score] = threshold_value\n",
    "\n",
    "    # Find the threshold @max metric score\n",
    "    metric_score_max_index = metric_threshold.index.max()\n",
    "    best_threshold = metric_threshold[metric_score_max_index]\n",
    "    print('=============================================')\n",
    "    print('Best threshold :', best_threshold)\n",
    "    print('Metric score   :', metric_score_max_index)\n",
    "    print('=============================================')\n",
    "    \n",
    "    # Dump file\n",
    "    utils.pickle_dump(best_threshold, CONFIG_DATA['best_threshold_path'])\n",
    "\n",
    "    return best_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================\n",
      "Best threshold : 0.48484848484848486\n",
      "Metric score   : 0.979375\n",
      "=============================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.48484848484848486"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Panggil fufngsi\n",
    "get_best_threshold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_valid' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m best_model \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mpickle_load(CONFIG_DATA[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_model_path\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Get the proba pred\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m y_pred_proba \u001b[38;5;241m=\u001b[39m best_model\u001b[38;5;241m.\u001b[39mpredict_proba(\u001b[43mX_valid\u001b[49m)[:, \u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_valid' is not defined"
     ]
    }
   ],
   "source": [
    "best_model = utils.pickle_load(CONFIG_DATA['best_model_path'])\n",
    "\n",
    "# Get the proba pred\n",
    "y_pred_proba = best_model.predict_proba(X_valid)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Sekarang tinggal dibuat `.py` file -nya"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fungsi `split_train_test`\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_preprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m preprocess_data\n\u001b[1;32m      3\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/output/data.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m data_clean \u001b[38;5;241m=\u001b[39m preprocess_data(X\u001b[38;5;241m=\u001b[39mdata, types\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m, CONFIG_DATA\u001b[38;5;241m=\u001b[39mCONFIG_DATA)\n",
      "File \u001b[0;32m~/documents/corporate_training/ahm/classification_project/src/data_preprocessing.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Import library\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils'"
     ]
    }
   ],
   "source": [
    "from src.data_preprocessing import preprocess_data\n",
    "\n",
    "data = pd.read_csv('data/output/data.csv')\n",
    "data_clean = preprocess_data(X=data, types='test', CONFIG_DATA=CONFIG_DATA)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
